#!/bin/bash

#
# This is a sample setup script. Rename this file to setup-$CONTAINER
# (where $container is the name of the container as defined in your config.yml),
# and replace this content with your own script.
#
# This script will be run when you setup the challenge.
#
# Remember that the exit code is important. See the documentation
# for more information.
#


cat <<EOF > license-secret.yaml
apiVersion: v1
data:
  license: IyBsaWNlbnNlX2ZpbGUueWFtbApjdXN0b21lck5hbWU6IGluc3RydXF0LWxhYnMtcDMtMjAzMDA4MTIKZGF0ZUVuZDogJzIwMzAtMDgtMTJUMDA6MDA6MDAuMDAwWicKZGF0ZVN0YXJ0OiAnMjAyMS0wOC0xM1QwMDowMDowMC4wMDBaJwpmZWF0dXJlczogbnVsbAppZDogZTI2NzI3MjYtNzMxZS00YzczLWJlYWQtMGU5ZjhiNGExNmY4CnByb2R1Y3Q6IEsxMApyZXN0cmljdGlvbnM6CiAgbm9kZXM6ICczJwpzZXJ2aWNlQWNjb3VudEtleTogbnVsbAp2ZXJzaW9uOiB2MS4wLjAKcHJvbW90aW9uSUQ6ICJtdWx0aXRlbmFuY3ktbGFiIgpzaWduYXR1cmU6IGJkL2tOcUp0azlMeC9YR1FQejZLK3E3aEhyMzNyaFRJMkRFZm90M3ZZYnpyUFVxT0RjWVhVVGRGNEFSM3RVbHlmaHdYUjVUS0hSRU5lK0ZST2NvUTN6WXpkK2d5cDU1M2tPaEhldVV0K2NpR1hhWU5VSnQ5c1NQVzhNakJwN20wL0Z6aGUxM0VkVUpwUUNXMlpGbnRWcUl1MThzY1FJWmsydlEyKzlPZEk3WTVJOFhiVUU0VlhiRk9XNWRyNWFQK2tBaStJUEJPWFhhSVp2L0g0dVlOMVNLMDlYT3FKSDlFMVZiYm1ZTHU5dHA0czRGekFmYU5JQTd0R0Rja3Q1SGpKUEZlbmhzM3RQWnpyVUI4VHVPVzdlY3Y5WVN1KzMzdmpqNXI1RWxWMHpUM0tvQnlmcGdLK0o5SjY2R1p6ZVRFM1A5ajZ4SjEzYUdDcUJ2Z1hYUVdFQT09
kind: Secret
metadata:
  creationTimestamp: null
  name: k10-license-labs
  namespace: kasten-io
EOF

# Wait for Kubernetes to be up and delete it to recreate it otherwise the default namespace will 
# have the same uid as the kubernetes on k8svm
# Wait for Kubernetes to be up
JSONPATH='{range .items[*]}{@.metadata.name}:{range @.status.conditions[*]}{@.type}={@.status};{end}{end}'
COUNTER=60
until [ $COUNTER -lt 0 ]; do
    echo "Waiting for Kubernetes to be ready... ${COUNTER}"
    kubectl get nodes -o jsonpath="$JSONPATH" | grep "Ready=True"
    if [[ $? -eq 0 ]] ; then
        kind delete cluster --name k10-demo
        break
    fi
    docker ps
    let COUNTER-=1
    sleep 5
done

kind delete cluster --name k10-demo

# recreate it 
cat > kind_config.yaml << EOF
kind: Cluster
apiVersion: kind.x-k8s.io/v1alpha4
nodes:
- role: control-plane
  image: kindest/node:v1.21.1
  extraPortMappings:
  - containerPort: 32000
    hostPort: 32000
    listenAddress: "0.0.0.0"
    protocol: TCP
  - containerPort: 32010
    hostPort: 32010
    listenAddress: "0.0.0.0"
    protocol: TCP
  - containerPort: 32020
    hostPort: 32020
    listenAddress: "0.0.0.0"
    protocol: TCP
  - containerPort: 32030
    hostPort: 32030
    listenAddress: "0.0.0.0"
    protocol: TCP
  - containerPort: 32040
    hostPort: 32040
    listenAddress: "0.0.0.0"
    protocol: TCP
  - containerPort: 32050
    hostPort: 32050
    listenAddress: "0.0.0.0"
    protocol: TCP
  - containerPort: 32060
    hostPort: 32060
    listenAddress: "0.0.0.0"
    protocol: TCP
  - containerPort: 32070
    hostPort: 32070
    listenAddress: "0.0.0.0"
    protocol: TCP
  - containerPort: 32080
    hostPort: 32080
    listenAddress: "0.0.0.0"
    protocol: TCP
  - containerPort: 32090
    hostPort: 32090
    listenAddress: "0.0.0.0"
    protocol: TCP
EOF

kind create cluster --name k10-demo --config=./kind_config.yaml --wait 600s

# Change to the latest supported snapshotter version
SNAPSHOTTER_VERSION=v4.2.1

# Apply VolumeSnapshot CRDs
kubectl apply -f https://raw.githubusercontent.com/kubernetes-csi/external-snapshotter/${SNAPSHOTTER_VERSION}/client/config/crd/snapshot.storage.k8s.io_volumesnapshotclasses.yaml
kubectl apply -f https://raw.githubusercontent.com/kubernetes-csi/external-snapshotter/${SNAPSHOTTER_VERSION}/client/config/crd/snapshot.storage.k8s.io_volumesnapshotcontents.yaml
kubectl apply -f https://raw.githubusercontent.com/kubernetes-csi/external-snapshotter/${SNAPSHOTTER_VERSION}/client/config/crd/snapshot.storage.k8s.io_volumesnapshots.yaml

# Create snapshot controller
kubectl apply -f https://raw.githubusercontent.com/kubernetes-csi/external-snapshotter/${SNAPSHOTTER_VERSION}/deploy/kubernetes/snapshot-controller/rbac-snapshot-controller.yaml
kubectl apply -f https://raw.githubusercontent.com/kubernetes-csi/external-snapshotter/${SNAPSHOTTER_VERSION}/deploy/kubernetes/snapshot-controller/setup-snapshot-controller.yaml

git clone https://github.com/kubernetes-csi/csi-driver-host-path.git
cd csi-driver-host-path || exit
./deploy/kubernetes-1.21/deploy.sh
kubectl apply -f ./examples/csi-storageclass.yaml
kubectl patch storageclass standard \
    -p '{"metadata": {"annotations":{"storageclass.kubernetes.io/is-default-class":"false"}}}'
kubectl patch storageclass csi-hostpath-sc \
    -p '{"metadata": {"annotations":{"storageclass.kubernetes.io/is-default-class":"true"}}}'




# https://github.com/NetApp/trident/issues/556
kubectl delete sc csi-hostpath-sc
cat <<EOF | kubectl create -f -
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  annotations:
    storageclass.kubernetes.io/is-default-class: "true"  
  name: csi-hostpath-sc
allowVolumeExpansion: true
provisioner: hostpath.csi.k8s.io
parameters:
  fsType: ext4  
reclaimPolicy: Delete
volumeBindingMode: Immediate
EOF

exit 0

